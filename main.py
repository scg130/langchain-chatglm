from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.document_loaders import TextLoader, DirectoryLoader
from langchain.chains import RetrievalQA
from llm_chatglm import ChatGLMLLM
import os

# åŠ è½½æ–‡æ¡£å¹¶åˆ‡åˆ†
def load_docs():
    loader = DirectoryLoader(
    "./data",
    glob="**/*.txt",                     # å¯è‡ªå®šä¹‰æ‰©å±•åï¼š*.md, *.csv, ç­‰
    loader_cls=TextLoader,
    loader_kwargs={"encoding": "utf-8"}  # é¿å…ç¼–ç æŠ¥é”™
)
    documents = loader.load()

    splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=50)
    docs = splitter.split_documents(documents)
    return docs

# æ„å»ºå‘é‡åº“
def build_vector_store(docs):
    embedding = HuggingFaceEmbeddings(model_name="shibing624/text2vec-base-chinese")
    vectordb = Chroma(persist_directory="./chroma_store", embedding_function=embedding)
    # vectordb.add_documents(docs)
    # vectordb.persist()
    return vectordb

# åˆå§‹åŒ– QA chain
def get_qa_chain(vectordb):
    retriever = vectordb.as_retriever(search_kwargs={"k": 3})
    llm = ChatGLMLLM()
    qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)
    return qa_chain

if __name__ == "__main__":
    if not os.path.exists("chroma_store/index"):
        print("ğŸ”„ æ­£åœ¨æ„å»ºå‘é‡åº“...")
        docs = load_docs()
        vectordb = build_vector_store(docs)
    else:
        print("âœ… åŠ è½½å·²æœ‰å‘é‡åº“...")
        embedding = HuggingFaceEmbeddings(model_name="shibing624/text2vec-base-chinese")
        vectordb = Chroma(persist_directory="./chroma_store", embedding_function=embedding)

    qa_chain = get_qa_chain(vectordb)

    while True:
        query = input("â“ ç”¨æˆ·é—®é¢˜ï¼š")
        if query.lower() in ["exit", "quit"]:
            break
        result = qa_chain.run(query)
        print("ğŸ’¡ ç­”æ¡ˆï¼š", result)
